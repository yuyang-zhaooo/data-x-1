{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter Grader\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-X Spring 2020: Homework 05\n",
    "\n",
    "### Scikit-Learn\n",
    "\n",
    "In this homework, you will do some exercises with prediction and plotting. \n",
    "\n",
    "Remember to store results in the variables defined, and don't reuse variables from a previous question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data:\n",
    "__Data Source__:\n",
    "Data file should be next to your notebook file called : __Energy.csv__\n",
    "\n",
    "The dataset was created by Angeliki Xifara ( Civil/Structural Engineer) and was processed by Athanasios Tsanas, Oxford Centre for Industrial and Applied Mathematics, University of Oxford, UK).\n",
    "\n",
    "__Data Description__:\n",
    "\n",
    "The dataset contains eight attributes of a building (or features, denoted by X1...X8) and response being the heating load on the building, y1. \n",
    "\n",
    "* X1\tRelative Compactness \n",
    "* X2\tSurface Area \n",
    "* X3\tWall Area \n",
    "*  X4\tRoof Area \n",
    "*  X5\tOverall Height \n",
    "* X6\tOrientation \n",
    "*  X7\tGlazing Area \n",
    "*  X8\tGlazing Area Distribution \n",
    "*  y1\tHeating Load \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1\n",
    "Let's read the data file in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "file_path='./Energy.csv'\n",
    "\n",
    "data=pd.read_csv(file_path)\n",
    "\n",
    "## Check top 5 rows of the data\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "__Q 1 a) Describe data features in terms of type, distribution range. Print out the rows for the count, mean, min, max indices (in *this exact* order) for each column in `data`. Store the output of the above operation result in a new variable called `distribution`.__\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distribution = ...\n",
    "distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "__Q1 b) Check if there are any NaN/null values. Store a boolean True or False in the variable `any_nulls`.__\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_nulls = ...\n",
    "any_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "__Q1 c) Separate the data into features and output labels.__\n",
    "\n",
    "Take the columns labelled X1 to X8 and store them in a new variable called `X`. Store the colum Y1 into a new variable called `Y`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "manual: true\n",
    "points: 5\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = ...\n",
    "Y = ...\n",
    "display(X.head())\n",
    "display(Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q1 d) Plot feature distributions. This step should give you clues about data sufficiency.__\n",
    "\n",
    "**Note:** This question is not graded, it's intended for your reference only.\n",
    "\n",
    "Your plotted image should look like this: <img src='./q1_c_expected.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSION\n",
    "\n",
    "Labels in the dataset provided are continuous values.\n",
    "Here the model is trained to predict a continuous value for each instance.\n",
    "On inputting a feature vector into the model, the trained model is able to predict a continuous value  for  that instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "__Q2 a): Pick 80% of the data for training and the rest for test.__\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "manual: true\n",
    "points: 5\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 100 # Dont change this line\n",
    "\n",
    "...\n",
    "print ('Number of samples in training data:',len(x_train))\n",
    "print ('Number of samples in validation data:',len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "__Q2 b) Train a linear regression model on the training data that you obtained above. What are the intercept and coefficient values of your linear model?.__\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# Create linear regression object\n",
    "...\n",
    "print ('INTERCEPT:',linearReg_model.intercept_)\n",
    "print ('COEFFICIENTS:\\n',linearReg_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "__Q.2 c): Report model performance using 'MEAN SQUARE' error metric on:__\n",
    "\n",
    "__1. Data that was used for training(Training error)__   \n",
    "\n",
    "__2. On the 20 percent of unseen data (Test error)__ \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2c\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error= ...\n",
    "print(\"Training Error (Mean squared error) :\",training_error)\n",
    "\n",
    "\n",
    "test_error= ...\n",
    "print(\"Test Error (Mean squared error) :\",test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "__Q2 d):__ \n",
    "\n",
    "Lets us see the effect of amount of data on the performance of prediction model. Use varying amounts of  Training data (100,200,300,400,500,all) to train regression models and report  training error and validation error in each case.\n",
    "\n",
    "**Plot error rates vs number of training examples.** Both the training error and the validation error should be plotted. Comment on the relationship you observe in the plot, between the amount of data used to train the model and the validation accuracy of the model.\n",
    "\n",
    "__Hint:__ Use array indexing to choose varying data amounts\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2d\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the data\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "sample_numbers= ...\n",
    "\n",
    "trainset_errors = list()\n",
    "validset_errors = list()\n",
    "\n",
    "# create a linear regression object and fit it using varying data amounts in a loop\n",
    "model_linear= ...\n",
    "\n",
    "for i in sample_numbers:\n",
    "    ...\n",
    "    \n",
    "# PLOT ERROR RATE:\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.plot(sample_numbers,trainset_errors,color=\"blue\", linewidth=1.0, linestyle=\"-\",marker='o',label='Training Error')\n",
    "plt.plot(sample_numbers,validset_errors,color=\"green\", linewidth=1.0, linestyle=\"-\",marker='o',label='Validation Error' )\n",
    "\n",
    "\n",
    "plt.xticks(sample_numbers)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Training sample size')\n",
    "plt.ylabel('Error')\n",
    "plt.title(\"Error Rate plot\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__CLASSIFICATION__:\n",
    "\n",
    "Labels are discrete values in classification tasks.\n",
    "\n",
    "Here the model is trained to classify each instance into a set of predefined  discrete classes.\n",
    "On inputting a feature vector into the model, the trained model is able to predict a  class of that instance. You can also output the probabilities of an instance belnging to a class.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "__Q 3 a):  Bucket values of `Y1` i.e `Heating Load`  from the original dataset into 3 classes:__ \n",
    "\n",
    "0: 'Low' ( < 14),   \n",
    "1: 'Medium'  (14-28),   \n",
    "2: 'High'  (>28)\n",
    "\n",
    "This converts the given dataset  into a classification problem, the classes being: Heating load is: *low, medium or high*. Use this datset with the transformed 'heating load' for creating a  logistic regression classifiction model that predicts heating load type of a building. Use test-train split ratio of 0.8 : 0.2.  \n",
    "\n",
    "*Report training and test accuracies in  confusion matrices.*\n",
    "\n",
    "\n",
    "**HINT:** Use pandas.cut\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a1\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "...\n",
    "Y_clas.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the cell below, split the dataset into training and test and fit a logistic regression model to the training data.\n",
    "Your training as well as test accuracy should be at least 75%. Make sure your test size is 20% of the dataset and your hyperparameter `C` for logistic regression is 0.001 (i.e 1e-3)\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a2\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "random_state=100 # Use this random state in your model\n",
    "C = ...\n",
    "test_size= ...\n",
    "\n",
    "...\n",
    "\n",
    "print ('Number of samples in training data:',len(xx1_train))\n",
    "print ('Number of samples in validation data:',len(xx1_test))\n",
    "\n",
    "# Name our regression object\n",
    "logreg_model = linear_model.LogisticRegression(C=C)\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "\n",
    "print ('Training a logistic Regression Model..')\n",
    "logreg_model.fit(xx1_train, yy1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the cell below, calculate the training and test accuracies.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a3\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report training and test accuracy\n",
    "training_accuracy= ...\n",
    "print ('Training Accuracy:',training_accuracy)\n",
    "\n",
    "\n",
    "test_accuracy= ...\n",
    "print ('Testing Accuracy:',test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the cell below, calculate the confusion matrix\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a4\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and report Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_train_pred = ...\n",
    "y_test_pred = ...\n",
    "\n",
    "train_confusion_matrix = confusion_matrix(yy1_train, y_train_pred)\n",
    "test_confusion_matrix = confusion_matrix(yy1_test, y_test_pred)\n",
    "\n",
    "print('Training Confusion Matrix \\n', train_confusion_matrix)\n",
    "print('Test Confusion Matrix \\n', test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "__Q3 b):__\n",
    "\n",
    "One of the preprocessing steps in Data science is Feature Scaling i.e getting all our data on the same scale by setting same  Min-Max of feature values. \n",
    "This makes training less sensitive to the scale of features . \n",
    "Scaling is important in algorithms that use distance based classification, SVM or K means or those that involve gradient descent optimization. If we  Scale features in the range [0,1] it is called unity based normalization.\n",
    "\n",
    "__Perform unity based normalization on the above dataset and train the model again, compare model performance in training and validation with your previous model.__  \n",
    "\n",
    "Refer:http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler  \n",
    "More at: https://en.wikipedia.org/wiki/Feature_scaling\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b1\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE\n",
    "def normalize(col):\n",
    "    return col_\n",
    "\n",
    "for col in ['X1','X2','X3','X4','X5','X6','X7','X8']:\n",
    "    X[col]=normalize(X[col])\n",
    "\n",
    "X1=X\n",
    "X1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the cell below, split the dataset into training and test and fit a logistic regression model to the training data.\n",
    "Once fitted, store the test and train accuracies in the `training_accuracy` and `test_accuracy` variables\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b2\n",
    "manual: true\n",
    "points: 4\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Split the train and testing data\n",
    "random_state=100 # don't change these lines\n",
    "test_size=0.15 # don't change these lines\n",
    "\n",
    "...\n",
    "\n",
    "print ('Number of samples in training data:',len(xx1_train))\n",
    "print ('Number of samples in validation data:',len(xx1_test))\n",
    "\n",
    "# Name our LOGISTIC regression object\n",
    "logreg_model = linear_model.LogisticRegression(C=1e5)\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "\n",
    "print ('Training a logistic Regression Model..')\n",
    "...\n",
    "\n",
    "training_accuracy= ...\n",
    "print ('Training Accuracy:', training_accuracy)\n",
    "\n",
    "\n",
    "test_accuracy= ...\n",
    "print ('Testing Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End\n",
    "Congratulations on finishing the homework! Remember to select Kernel -> Restart and Run all before submitting your `.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "data-x"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}